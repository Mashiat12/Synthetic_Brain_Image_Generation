{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87X0S2ERZMZc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(0)\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKPh52fQKTuJ"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib-venn\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq1hxlJdKjnu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.animation as animation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIkt5BRoNnfk"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import glob\n",
        "import imageio\n",
        "import cv2\n",
        "import pathlib\n",
        "import sys\n",
        "from skimage import io, transform\n",
        "from IPython import display\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "vUO60cZYk6jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9K5SSVpNi07"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from zipfile import ZipFile\n",
        "from __future__ import print_function\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz5X5qW5Idl-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, TensorDataset\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7yS_fdVOM3-"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.utils as vutils\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxNyctIhNXx2"
      },
      "outputs": [],
      "source": [
        "manualSeed = 999\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG6WIcQdZ8rG"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA is available. Using GPU.\")\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        print(\"CUDA is not available. Using CPU.\")\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjriwCmsaK9T"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q7lyHjNPEPJ"
      },
      "outputs": [],
      "source": [
        "kaggle_credentails= json.load(open(\"/content/drive/MyDrive/kaggle.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbdzzIYpPLZf"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = kaggle_credentails['username']\n",
        "os.environ['KAGGLE_KEY'] = kaggle_credentails['key']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jVnqgGrPPvt"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d ashfakyeafi/brain-mri-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXDE4_OCPZq5"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(\"/content/brain-mri-images.zip\",'r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rFme-VRPqPI"
      },
      "outputs": [],
      "source": [
        "print(\"Length of directory : \",len(os.listdir(\"/content/GAN-Traning Images\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVO6j0XAaqUN"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not load image at {img_path}. Please check the file path.\")\n",
        "        return None\n",
        "\n",
        "    # Converting to grayscale\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Denoising\n",
        "    denoised_img = cv2.fastNlMeansDenoising(gray_img, None, 20, 3, 21)\n",
        "\n",
        "    # Sharpening using a custom kernel\n",
        "    kernel_sharpen = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
        "    sharpened_img = cv2.filter2D(denoised_img, -1, kernel_sharpen)\n",
        "\n",
        "    return sharpened_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coc9vGIRQjha"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(image_dir, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for img_name in os.listdir(image_dir):\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "        processed_img = preprocess_image(img_path)\n",
        "\n",
        "        if processed_img is not None:\n",
        "            output_path = os.path.join(output_dir, img_name)\n",
        "            cv2.imwrite(output_path, processed_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB8tykAKa7-B"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(9, 9))\n",
        "img_path = '/content/GAN-Traning Images/OAS2_0001_MR2_y_slice_105.jpg'\n",
        "img1=mpimg.imread(img_path)\n",
        "ax[0].imshow(img1 , cmap='gray')\n",
        "ax[0].set_title('Original MRI Image')\n",
        "ax[0].axis('on')\n",
        "preprocessed_img = preprocess_image(img_path)\n",
        "ax[1].imshow(preprocessed_img, cmap='gray')\n",
        "ax[1].set_title('Enhanced MRI Image')\n",
        "ax[1].axis('on')\n",
        "\n",
        "plt.show()\n",
        "ax[1].imshow(preprocessed_img, cmap='gray')\n",
        "ax[1].set_title('Enhanced MRI Image')\n",
        "ax[1].axis('on')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF_cHA97Q3JX"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(8,8))\n",
        "img_path = '/content/GAN-Traning Images/OAS2_0023_MR2_z_slice_137.jpg'\n",
        "img1=mpimg.imread(img_path)\n",
        "ax[0].imshow(img1 , cmap='gray')\n",
        "ax[0].set_title('Original MRI Image')\n",
        "ax[0].axis('on')\n",
        "preprocessed_img = preprocess_image(img_path)\n",
        "ax[1].imshow(preprocessed_img, cmap='gray')\n",
        "ax[1].set_title('Enhanced MRI Image')\n",
        "ax[1].axis('on')\n",
        "\n",
        "plt.show()\n",
        "ax[1].imshow(preprocessed_img, cmap='gray')\n",
        "ax[1].set_title('Enhanced MRI Image')\n",
        "ax[1].axis('on')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmn8G2k4R1nE"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(9, 9))\n",
        "img_path = '/content/GAN-Traning Images/OAS2_0008_MR1_x_slice_134.jpg'\n",
        "img1=mpimg.imread(img_path)\n",
        "ax[0].imshow(img1 , cmap='gray')\n",
        "ax[0].set_title('Original MRI Image')\n",
        "ax[0].axis('on')\n",
        "preprocessed_img = preprocess_image(img_path)\n",
        "ax[1].imshow(preprocessed_img, cmap='gray')\n",
        "ax[1].set_title('Enhanced MRI Image')\n",
        "ax[1].axis('on')\n",
        "\n",
        "plt.show()\n",
        "ax[1].imshow(preprocessed_img, cmap='gray')\n",
        "ax[1].set_title('Enhanced MRI Image')\n",
        "ax[1].axis('on')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R5dmy3Hbeas"
      },
      "outputs": [],
      "source": [
        "image_dir = \"/content/GAN-Traning Images\"\n",
        "output_dir = \"/content/processed_images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5xKJbFHVLZV"
      },
      "outputs": [],
      "source": [
        "preprocess_dataset(image_dir, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kmRB3kHz8sd"
      },
      "outputs": [],
      "source": [
        "source_dir = '/content/processed_images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZEGovNYYo14"
      },
      "outputs": [],
      "source": [
        "destination_dir = '/content/drive/MyDrive/out/output_brain'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdt3PrO-math"
      },
      "outputs": [],
      "source": [
        "print(\"Length of destination directory : \",len(os.listdir(destination_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLWdH28zU8OT"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.copytree(source_dir, destination_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxEEJW2sbu2r"
      },
      "outputs": [],
      "source": [
        "def convert_to_tensor(img_path):\n",
        "    img = Image.open(img_path).convert('L')\n",
        "    transform = T.Compose([\n",
        "        T.Resize((64, 64)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    img_tensor = transform(img)\n",
        "    return img_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QiorDpGb6Y_"
      },
      "outputs": [],
      "source": [
        "def load_and_convert_images(image_dir):\n",
        "    tensors = []\n",
        "\n",
        "    for img_name in os.listdir(image_dir):\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "        img_tensor = convert_to_tensor(img_path)\n",
        "        tensors.append(img_tensor)\n",
        "\n",
        "    return tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI4aLbPqb8d2"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "preprocessed_tensors = load_and_convert_images(destination_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwsXq2WV3Zms"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhRilyJC3LIM"
      },
      "outputs": [],
      "source": [
        "preprocessed_dataset = TensorDataset(torch.stack(preprocessed_tensors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oiw0SP4i6R5Y"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/out'\n",
        "print(os.listdir(DATA_DIR))\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phzVYpbU3czP"
      },
      "outputs": [],
      "source": [
        "image_size=64\n",
        "batch_size=128\n",
        "stats=(0.5,0.5,0.5),(0.5,0.5,0.5)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0bbDRp_6QAR"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIwoIwBZ5KLY"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "train_ds= ImageFolder(DATA_DIR,transform=T.Compose([T.Resize(image_size),T.CenterCrop(image_size),T.ToTensor(),T.Normalize(*stats)]))\n",
        "train_dl =DataLoader(train_ds,batch_size,shuffle=True,num_workers=3,pin_memory=True)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcpYotkW6zhu"
      },
      "outputs": [],
      "source": [
        "def denorm(img_tensors):\n",
        "  return img_tensors * stats[1][0]+stats[0][0]\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQHSB5IT69i_"
      },
      "outputs": [],
      "source": [
        "def show_images(images,nmax=64):\n",
        "  fig,ax=plt.subplots(figsize=(8,8))\n",
        "  ax.set_xticks([]);\n",
        "  ax.set_yticks([])\n",
        "  ax.imshow(make_grid(denorm(images.detach()[:nmax]),nrow=8).permute(1,2,0))\n",
        "\n",
        "def show_batch(dl,nmax=64):\n",
        "  for images,_ in dl:\n",
        "    show_images(images,nmax)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhV_10OW6_X2"
      },
      "outputs": [],
      "source": [
        "show_batch(train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCMZhWIN7I4v"
      },
      "outputs": [],
      "source": [
        "discriminator =nn.Sequential(\n",
        "    nn.Conv2d(3,64,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "    nn.Conv2d(64,128,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "    nn.Conv2d(128,256,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "    nn.Conv2d(256,512,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "    nn.Conv2d(512,1,kernel_size=4,stride=1,padding=0,bias=False),\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ANxRe_W7Q-F"
      },
      "outputs": [],
      "source": [
        "discriminator = to_device(discriminator,device)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "XQTqT21fki0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDgFKFFw7ooe"
      },
      "outputs": [],
      "source": [
        "latent_size=128\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE1j-aJw7woE"
      },
      "outputs": [],
      "source": [
        "generator=nn.Sequential(\n",
        "    nn.ConvTranspose2d(latent_size,512,kernel_size=4,stride=1,padding=0,bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(512,256,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(256,128,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(64,3,kernel_size=4,stride=2,padding=1,bias=False),\n",
        "    nn.Tanh(),\n",
        ")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SJq1RPa7zAF"
      },
      "outputs": [],
      "source": [
        "xb=torch.randn(batch_size,latent_size,1,1)\n",
        "print(xb.shape)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HUiV-d476Xs"
      },
      "outputs": [],
      "source": [
        "fake_images=generator(xb)\n",
        "print(fake_images.shape)\n",
        "show_images(fake_images)\n",
        "#summary(generator, input_size=(batch_size, latent_size, 1, 1))\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqk5KHP_8JZ8"
      },
      "outputs": [],
      "source": [
        "generator=to_device(generator,device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "a4Tp_Qh5lJ_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bprwml708Rp0"
      },
      "outputs": [],
      "source": [
        "def train_discriminator(real_images,opt_d):\n",
        "  opt_d.zero_grad()\n",
        "  real_images=real_images.to(device)\n",
        "  real_preds= discriminator(real_images)\n",
        "  real_targets=torch.ones(real_images.size(0),1,device=device)\n",
        "  real_loss= F.binary_cross_entropy(real_preds,real_targets)\n",
        "  real_score=torch.mean(real_preds).item()\n",
        "\n",
        "  latent=torch.randn(batch_size,latent_size,1,1,device=device)\n",
        "  fake_images=generator(latent)\n",
        "\n",
        "  fake_targets= torch.zeros(fake_images.size(0),1,device=device)\n",
        "  fake_preds= discriminator(fake_images)\n",
        "  fake_loss= F.binary_cross_entropy(fake_preds,fake_targets)\n",
        "  fake_score=torch.mean(fake_preds).item()\n",
        "\n",
        "  loss=real_loss + fake_loss\n",
        "  loss.backward()\n",
        "  opt_d.step()\n",
        "  return loss.item(),real_score,fake_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgnVexQI8T1c"
      },
      "outputs": [],
      "source": [
        "def train_generator(opt_g):\n",
        "  opt_g.zero_grad()\n",
        "\n",
        "  latent=torch.randn(batch_size,latent_size,1,1,device=device)\n",
        "  fake_images=generator(latent)\n",
        "  preds= discriminator(fake_images)\n",
        "  targets=torch.ones(batch_size,1,device=device)\n",
        "  loss= F.binary_cross_entropy(preds,targets)\n",
        "  loss.backward()\n",
        "  opt_g.step()\n",
        "  return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHIVFFMS8ZMr"
      },
      "outputs": [],
      "source": [
        "sample_dir='generated'\n",
        "os.makedirs(sample_dir,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro8VMudN8lWj"
      },
      "outputs": [],
      "source": [
        "def save_samples(index,latent_tensors,show=True):\n",
        "  fake_images=generator(latent_tensors)\n",
        "  fake_fname='generated-images-{0:0=4d}.png'.format(index)\n",
        "  save_image(denorm(fake_images),os.path.join(sample_dir,fake_fname),nrow=8)\n",
        "  print('Saving',fake_fname)\n",
        "  if show:\n",
        "    fig,ax=plt.subplots(figsize=(8,8))\n",
        "    ax.set_xticks([]);ax.set_yticks([])\n",
        "    ax.imshow(make_grid(fake_images.cpu().detach(),nrow=8).permute(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRJte4xc8qKL"
      },
      "outputs": [],
      "source": [
        "fixed_latent= torch.randn(64,latent_size,1,1,device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Di0JnD85tq"
      },
      "outputs": [],
      "source": [
        "save_samples(0,fixed_latent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y2rpAbg9EjC"
      },
      "outputs": [],
      "source": [
        "save_samples(10,fixed_latent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbhyRnlC9MhL"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smCkDLn69WQB"
      },
      "outputs": [],
      "source": [
        "def fit(epochs,lr,start_idx=1):\n",
        "  torch.cuda.empty_cache()\n",
        "  losses_g=[]\n",
        "  losses_d=[]\n",
        "  real_scores=[]\n",
        "  fake_scores=[]\n",
        "\n",
        "  opt_d=torch.optim.Adam(discriminator.parameters(),lr=lr,betas=(0.5,0.999))\n",
        "  opt_g=torch.optim.Adam(generator.parameters(),lr=lr,betas=(0.5,0.999))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for real_images, _ in tqdm(train_dl):\n",
        "      loss_d,real_score,fake_score= train_discriminator(real_images,opt_d)\n",
        "      loss_g = train_generator(opt_g)\n",
        "\n",
        "    losses_g.append(loss_g)\n",
        "    losses_d.append(loss_d)\n",
        "    real_scores.append(real_score)\n",
        "    fake_scores.append(fake_score)\n",
        "    print(\"Epoch[{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "\n",
        "    save_samples(epoch+start_idx,fixed_latent,show=False)\n",
        "  return losses_g,losses_d,real_scores,fake_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS35zFXK9ZRI"
      },
      "outputs": [],
      "source": [
        "lr =0.0002\n",
        "epochs=25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXpcOULF9kEY"
      },
      "outputs": [],
      "source": [
        "history= fit(epochs,lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf93QDCn-JG3"
      },
      "outputs": [],
      "source": [
        "losses_g,losses_d,real_scores,fake_scores=history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfYh8Omw-RgG"
      },
      "outputs": [],
      "source": [
        "torch.save(generator.state_dict(),'Generator.pth')\n",
        "torch.save(discriminator.state_dict(),'Discriminator.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqubHWdG-XJu"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGiJDnAz92rO"
      },
      "outputs": [],
      "source": [
        "Image('./generated/generated-images-0001.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "drive_dir = '/content/drive/MyDrive/GAN_metrics2/'\n",
        "import os\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "with open(drive_dir + 'losses_g.json', 'w') as f:\n",
        "    json.dump(losses_g, f)\n",
        "with open(drive_dir + 'losses_d.json', 'w') as f:\n",
        "    json.dump(losses_d, f)\n",
        "with open(drive_dir + 'real_scores.json', 'w') as f:\n",
        "    json.dump(real_scores, f)\n",
        "with open(drive_dir + 'fake_scores.json', 'w') as f:\n",
        "    json.dump(fake_scores, f)"
      ],
      "metadata": {
        "id": "Y3vzPBPeQ70b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "drive_dir = '/content/drive/MyDrive/GAN_metrics2/'\n",
        "with open(drive_dir + 'losses_g.json', 'r') as f:\n",
        "    losses_g = json.load(f)\n",
        "with open(drive_dir + 'losses_d.json', 'r') as f:\n",
        "    losses_d = json.load(f)\n",
        "with open(drive_dir + 'real_scores.json', 'r') as f:\n",
        "    real_scores = json.load(f)\n",
        "with open(drive_dir + 'fake_scores.json', 'r') as f:\n",
        "    fake_scores = json.load(f)\n",
        "\n",
        "epochs = len(losses_g)\n",
        "def plot_training_metrics(losses_g, losses_d, real_scores, fake_scores, epochs):\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.title(\"GAN Training Metrics\")\n",
        "    plt.plot(losses_g, label=\"Generator Loss\")\n",
        "    plt.plot(losses_d, label=\"Discriminator Loss\")\n",
        "    plt.plot(real_scores, label=\"Real Image Scores\")\n",
        "    plt.plot(fake_scores, label=\"Fake Image Scores\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Score/Loss\")\n",
        "    plt.xlim(-1, 25)\n",
        "    plt.ylim(-1.5, 17.4)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "plot_training_metrics(losses_g, losses_d, real_scores, fake_scores,epochs)"
      ],
      "metadata": {
        "id": "Leb4gV9heNDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image('./generated/generated-images-0025.png')"
      ],
      "metadata": {
        "id": "BVDApnPNAgLp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}